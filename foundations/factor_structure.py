# # foundations/factor_structure.py

# import re
# from typing import List, Union, Any, Set
# # alpha_zoo.pyì—ì„œ íŒ©í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ import ì¶”ê°€
# from .alpha_zoo import get_alpha_zoo

# # --- AST ë…¸ë“œ í´ë˜ìŠ¤ ì •ì˜ (ì´ì „ ì½”ë“œì™€ ë™ì¼) ---
# class ASTNode:
#     """ëª¨ë“  AST ë…¸ë“œì˜ ê¸°ë³¸ì´ ë˜ëŠ” ì¶”ìƒ í´ë˜ìŠ¤ì…ë‹ˆë‹¤."""
#     def __repr__(self):
#         return self.__str__()
    
#     # hashableí•˜ê²Œ ë§Œë“¤ì–´ setì— ì €ì¥í•  ìˆ˜ ìˆë„ë¡ í•¨
#     def __hash__(self):
#         return hash(str(self))

#     def __eq__(self, other):
#         return str(self) == str(other)

# class OperatorNode(ASTNode):
#     """ì—°ì‚°ì(e.g., rank, +, -)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë…¸ë“œì…ë‹ˆë‹¤."""
#     def __init__(self, op: str, children: List[ASTNode]):
#         self.op = op
#         self.children = children

#     def __str__(self):
#         children_str = ', '.join(map(str, self.children))
#         return f"{self.op}({children_str})"

# class VariableNode(ASTNode):
#     """ë³€ìˆ˜(e.g., close, volume)ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë…¸ë“œì…ë‹ˆë‹¤."""
#     def __init__(self, name: str):
#         self.name = name

#     def __str__(self):
#         return f"${self.name}"

# class LiteralNode(ASTNode):
#     """ë¦¬í„°ëŸ´(ìƒìˆ˜ ê°’, e.g., 10, 'sector')ì„ ë‚˜íƒ€ë‚´ëŠ” ë…¸ë“œì…ë‹ˆë‹¤."""
#     def __init__(self, value: Any):
#         self.value = value

#     def __str__(self):
#         if isinstance(self.value, str):
#             return f'"{self.value}"'
#         return str(self.value)

# # --- íŒ©í„° ê³µì‹ íŒŒì„œ (ì´ì „ ì½”ë“œì™€ ë™ì¼) ---
# class FactorParser:
#     """
#     íŒ©í„° ê³µì‹ ë¬¸ìì—´ì„ ASTë¡œ ë³€í™˜í•˜ëŠ” íŒŒì„œì…ë‹ˆë‹¤.
#     """
#     # (ì´ì „ ë‹¨ê³„ì—ì„œ ì‘ì„±í•œ FactorParser í´ë˜ìŠ¤ ì½”ë“œê°€ ì—¬ê¸°ì— ìœ„ì¹˜í•©ë‹ˆë‹¤. ìƒëµ)
#     def __init__(self):
#         self.tokens = []
#         self.pos = 0

#     def parse(self, formula: str) -> ASTNode:
#         self.tokens = self._tokenize(formula)
#         self.pos = 0
#         ast = self._parse_expression()
#         if self.pos < len(self.tokens):
#             raise ValueError("íŒŒì‹± í›„ ë‚¨ì€ í† í°ì´ ìˆìŠµë‹ˆë‹¤: {}".format(self.tokens[self.pos:]))
#         return ast

#     def _tokenize(self, formula: str) -> List[str]:
#         token_regex = re.compile(r'([A-Za-z_][A-Za-z0-9_\.]*|\d+\.?\d*|==|!=|<=|>=|&&|\|\||[()+\-*/?^:,<>])')
#         tokens = token_regex.findall(formula)
#         return [token for token in tokens if token.strip() and token != '$']

#     def _peek(self) -> Union[str, None]:
#         return self.tokens[self.pos] if self.pos < len(self.tokens) else None

#     def _consume(self) -> str:
#         token = self._peek()
#         self.pos += 1
#         return token

#     def _parse_primary(self) -> ASTNode:
#         token = self._peek()
#         if token == '-':
#             self._consume()
#             return OperatorNode('neg', [self._parse_primary()])
#         if token.replace('.', '', 1).isdigit():
#             return LiteralNode(float(self._consume()))
#         if token.isalnum() or '_' in token or '.' in token:
#             self._consume()
#             if self._peek() == '(':
#                 self._consume()
#                 args = []
#                 if self._peek() != ')':
#                     while True:
#                         args.append(self._parse_expression())
#                         if self._peek() == ')':
#                             break
#                         if self._peek() != ',':
#                             raise ValueError("í•¨ìˆ˜ ì¸ì ì‚¬ì´ì— ì½¤ë§ˆ(,)ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
#                         self._consume()
#                 self._consume()
#                 return OperatorNode(token, args)
#             else:
#                 return VariableNode(token)
#         if token == '(':
#             self._consume()
#             expr = self._parse_expression()
#             if self._consume() != ')':
#                 raise ValueError("ê´„í˜¸ê°€ ë‹«íˆì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
#             return expr
#         raise ValueError(f"ì˜ˆìƒì¹˜ ëª»í•œ í† í°ì…ë‹ˆë‹¤: {token}")

#     def _parse_binary_op(self, parse_next_level, ops: List[str]) -> ASTNode:
#         node = parse_next_level()
#         while self._peek() in ops:
#             op = self._consume()
#             right = parse_next_level()
#             node = OperatorNode(op, [node, right])
#         return node

#     def _parse_power(self) -> ASTNode:
#         return self._parse_binary_op(self._parse_primary, ['^'])

#     def _parse_multiplicative(self) -> ASTNode:
#         return self._parse_binary_op(self._parse_power, ['*', '/'])

#     def _parse_additive(self) -> ASTNode:
#         return self._parse_binary_op(self._parse_multiplicative, ['+', '-'])
        
#     def _parse_comparison(self) -> ASTNode:
#         return self._parse_binary_op(self._parse_additive, ['>', '<', '>=', '<=', '==', '!='])

#     def _parse_logical(self) -> ASTNode:
#         return self._parse_binary_op(self._parse_comparison, ['&&', '||'])

#     def _parse_expression(self) -> ASTNode:
#         node = self._parse_logical()
#         if self._peek() == '?':
#             self._consume()
#             true_expr = self._parse_expression()
#             if self._consume() != ':':
#                 raise ValueError("ì‚¼í•­ ì—°ì‚°ìì— ':'ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
#             false_expr = self._parse_expression()
#             return OperatorNode('If', [node, true_expr, false_expr])
#         return node

# # --- íŒ©í„° ë³µì¡ë„ ë¶„ì„ê¸° (ì´ì „ ì½”ë“œì™€ ë™ì¼) ---
# class ComplexityAnalyzer:
#     """ASTë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒ©í„°ì˜ ë³µì¡ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
#     # (ì´ì „ ë‹¨ê³„ì—ì„œ ì‘ì„±í•œ ComplexityAnalyzer í´ë˜ìŠ¤ ì½”ë“œê°€ ì—¬ê¸°ì— ìœ„ì¹˜í•©ë‹ˆë‹¤. ìƒëµ)
#     def calculate_symbolic_length(self, node: ASTNode) -> int:
#         if isinstance(node, OperatorNode):
#             return 1 + sum(self.calculate_symbolic_length(child) for child in node.children)
#         return 1

#     def calculate_parameter_count(self, node: ASTNode) -> int:
#         count = 0
#         if isinstance(node, LiteralNode) and isinstance(node.value, (int, float)):
#             count = 1
#         if isinstance(node, OperatorNode):
#             count += sum(self.calculate_parameter_count(child) for child in node.children)
#         return count


# # --- íŒ©í„° ë…ì°½ì„± ë¶„ì„ê¸° (ì‹ ê·œ ì¶”ê°€) ---

# class OriginalityAnalyzer:
#     """
#     AST ë¹„êµë¥¼ í†µí•´ íŒ©í„°ì˜ ë…ì°½ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.
#     Alpha Zooì— ìˆëŠ” ê¸°ì¡´ íŒ©í„°ë“¤ê³¼ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
#     """
#     def __init__(self, parser: FactorParser, complexity_analyzer: ComplexityAnalyzer):
#         """
#         ì´ˆê¸°í™” ì‹œ Alpha Zooì˜ ëª¨ë“  íŒ©í„°ë¥¼ íŒŒì‹±í•˜ì—¬ AST í˜•íƒœë¡œ ì €ì¥í•´ ë‘¡ë‹ˆë‹¤.
#         """
#         self.parser = parser
#         self.complexity_analyzer = complexity_analyzer
#         self.alpha_zoo_asts = self._load_alpha_zoo_asts()

#     def _load_alpha_zoo_asts(self) -> List[ASTNode]:
#         """Alpha Zooì˜ íŒ©í„° ê³µì‹ë“¤ì„ ASTë¡œ ë³€í™˜í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
#         formulas = get_alpha_zoo()
#         asts = []
#         for formula in formulas:
#             try:
#                 asts.append(self.parser.parse(formula))
#             except Exception as e:
#                 # 101 Alphaì˜ ì¼ë¶€ í‘œí˜„ì‹ì€ êµ¬í˜„ëœ íŒŒì„œê°€ ì²˜ë¦¬ ëª»í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì˜¤ë¥˜ ë°œìƒ ì‹œ ê²½ê³ ë§Œ ì¶œë ¥
#                 # print(f"ê²½ê³ : Alpha Zoo íŒ©í„° '{formula}' íŒŒì‹± ì‹¤íŒ¨: {e}")
#                 pass
#         return asts

#     def _are_isomorphic(self, node1: ASTNode, node2: ASTNode) -> bool:
#         """ë‘ AST (ë˜ëŠ” ì„œë¸ŒíŠ¸ë¦¬)ê°€ êµ¬ì¡°ì ìœ¼ë¡œ ë™ì¼í•œì§€ ì¬ê·€ì ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤."""
#         if type(node1) is not type(node2):
#             return False

#         if isinstance(node1, OperatorNode):
#             # OperatorNodeì¸ ê²½ìš°
#             return (node1.op == node2.op and
#                     len(node1.children) == len(node2.children) and
#                     all(self._are_isomorphic(c1, c2) for c1, c2 in zip(node1.children, node2.children)))
#         elif isinstance(node1, VariableNode):
#             # VariableNodeì¸ ê²½ìš°
#             return node1.name == node2.name
#         elif isinstance(node1, LiteralNode):
#             # LiteralNodeì¸ ê²½ìš°
#             return node1.value == node2.value
#         return False

#     def _get_all_subtrees(self, node: ASTNode) -> Set[ASTNode]:
#         """ì£¼ì–´ì§„ ASTì—ì„œ ëª¨ë“  ê°€ëŠ¥í•œ ì„œë¸ŒíŠ¸ë¦¬ë“¤ì„ set í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
#         subtrees = {node}
#         if isinstance(node, OperatorNode):
#             for child in node.children:
#                 subtrees.update(self._get_all_subtrees(child))
#         return subtrees

#     def calculate_similarity_score(self, new_factor_ast: ASTNode) -> float:
#         """
#         ìƒˆë¡œìš´ íŒ©í„°ê°€ Alpha Zooì˜ íŒ©í„°ë“¤ê³¼ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ ê³„ì‚°í•©ë‹ˆë‹¤.
#         ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (0: ì™„ì „ ë‹¤ë¦„, 1: ì™„ì „ ë™ì¼)

#         Args:
#             new_factor_ast (ASTNode): ë…ì°½ì„±ì„ í‰ê°€í•  ìƒˆë¡œìš´ íŒ©í„°ì˜ ASTì…ë‹ˆë‹¤.

#         Returns:
#             float: Alpha Zoo ë‚´ íŒ©í„°ë“¤ê³¼ì˜ ìµœëŒ€ ìœ ì‚¬ë„ ì ìˆ˜ (S(f)).
#         """
#         max_similarity = 0.0
#         new_factor_subtrees = self._get_all_subtrees(new_factor_ast)
#         size_new = self.complexity_analyzer.calculate_symbolic_length(new_factor_ast)

#         for zoo_ast in self.alpha_zoo_asts:
#             zoo_subtrees = self._get_all_subtrees(zoo_ast)
            
#             # ê³µí†µ ì„œë¸ŒíŠ¸ë¦¬ ì°¾ê¸°
#             common_subtrees = new_factor_subtrees.intersection(zoo_subtrees)
            
#             if not common_subtrees:
#                 continue
            
#             # ê°€ì¥ í° ê³µí†µ ì„œë¸ŒíŠ¸ë¦¬ì˜ í¬ê¸° ê³„ì‚°
#             largest_common_subtree_size = 0
#             for sub in common_subtrees:
#                 # is_isomorphicì€ setì— ë„£ì„ ë•Œ ì´ë¯¸ ì•”ì‹œì ìœ¼ë¡œ ê²€ì‚¬ë˜ì—ˆì§€ë§Œ, ëª…í™•ì„±ì„ ìœ„í•´ ë¡œì§ ìœ ì§€
#                 # ì‹¤ì œë¡œëŠ” common_subtreesì— ìˆëŠ” ê²ƒë§Œìœ¼ë¡œë„ ë™ì¼ êµ¬ì¡°ì„ì´ ë³´ì¥ë¨.
#                 size = self.complexity_analyzer.calculate_symbolic_length(sub)
#                 if size > largest_common_subtree_size:
#                     largest_common_subtree_size = size

#             # ì •ê·œí™”ëœ ìœ ì‚¬ë„ ê³„ì‚° (ë…¼ë¬¸ Eq.5 ì°¸ê³ , ë‹¨ ë¶„ëª¨ëŠ” max(|T(fi)|, |T(fj)|) ëŒ€ì‹  ë‘ ì‚¬ì´ì¦ˆì˜ í‰ê·  ì‚¬ìš©)
#             # ì´ëŠ” í•œìª½ì´ ë§¤ìš° í´ ë•Œ ìœ ì‚¬ë„ê°€ ê³¼ì†Œí‰ê°€ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•¨. ë…¼ë¬¸ì˜ ìˆ˜ì‹ì„ ì—„ê²©íˆ ë”°ë¥¼ ìˆ˜ë„ ìˆìŒ.
#             size_zoo = self.complexity_analyzer.calculate_symbolic_length(zoo_ast)
#             # ë…¼ë¬¸ì˜ ìˆ˜ì‹ì„ ë” ì •í™•íˆ ë”°ë¥´ê¸° ìœ„í•´ maxë¡œ ë¶„ëª¨ë¥¼ ê³„ì‚°
#             # similarity = largest_common_subtree_size / max(size_new, size_zoo)
            
#             # ì¢€ ë” ì§ê´€ì ì¸ ì •ê·œí™”ë¥¼ ìœ„í•´ ë‘ íŠ¸ë¦¬ì˜ í¬ê¸° í•©ìœ¼ë¡œ ë‚˜ëˆ”
#             # ì´ëŠ” ë‘ íŠ¸ë¦¬ì˜ ê³µí†µ ë¶€ë¶„ì˜ ë¹„ìœ¨ì„ ë‚˜íƒ€ëƒ„
#             similarity = (2 * largest_common_subtree_size) / (size_new + size_zoo)


#             if similarity > max_similarity:
#                 max_similarity = similarity
        
#         return max_similarity

# '''
# # --- í…ŒìŠ¤íŠ¸ ì½”ë“œ ---
# if __name__ == '__main__':
#     parser = FactorParser()
#     complexity_analyzer = ComplexityAnalyzer()
    
#     # 1. ì´ì „ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
#     sample_formula = "(rank((open - (sum(vwap, 10) / 10))) * (-1 * abs(rank((close - vwap)))))"
#     print("="*50)
#     print(f"í…ŒìŠ¤íŠ¸ ê³µì‹ 1: {sample_formula}")
#     print("="*50)
#     ast_tree = parser.parse(sample_formula)
#     print("\n[íŒŒì„œ & ë³µì¡ë„ í…ŒìŠ¤íŠ¸]")
#     print(f"AST: {ast_tree}")
#     print(f"ìƒì§•ì  ê¸¸ì´: {complexity_analyzer.calculate_symbolic_length(ast_tree)}")
#     print(f"íŒŒë¼ë¯¸í„° ê°œìˆ˜: {complexity_analyzer.calculate_parameter_count(ast_tree)}")

#     # 2. ë…ì°½ì„± ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸
#     print("\n" + "="*50)
#     print("[ë…ì°½ì„± ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸]")
#     print("="*50)
#     originality_analyzer = OriginalityAnalyzer(parser, complexity_analyzer)
#     print(f"Alpha Zoo ë¡œë“œ ì™„ë£Œ: ì´ {len(originality_analyzer.alpha_zoo_asts)}ê°œ íŒ©í„° AST")
    
#     # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: Alpha Zooì— ìˆëŠ” íŒ©í„°ì™€ ê±°ì˜ ë™ì¼í•œ íŒ©í„° (Alpha#6)
#     similar_formula = "(-1 * correlation(open, volume, 10))" # Alpha#6ê³¼ ë™ì¼
#     similar_ast = parser.parse(similar_formula)
#     similarity1 = originality_analyzer.calculate_similarity_score(similar_ast)
#     print(f"\ní…ŒìŠ¤íŠ¸ ê³µì‹ 2 (ìœ ì‚¬ë„ ë†’ìŒ ì˜ˆìƒ): {similar_formula}")
#     print(f"-> Alpha Zooì™€ì˜ ìœ ì‚¬ë„ ì ìˆ˜: {similarity1:.4f} (1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)")

#     # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: Alpha Zooì— ìˆëŠ” íŒ©í„°ì™€ êµ¬ì¡°ê°€ ì•½ê°„ ë‹¤ë¥¸ íŒ©í„°
#     modified_formula = "(-1 * correlation(high, volume, 10))" # Alpha#6ì—ì„œ openì„ highë¡œ ë³€ê²½
#     modified_ast = parser.parse(modified_formula)
#     similarity2 = originality_analyzer.calculate_similarity_score(modified_ast)
#     print(f"\ní…ŒìŠ¤íŠ¸ ê³µì‹ 3 (ìœ ì‚¬ë„ ì¤‘ê°„ ì˜ˆìƒ): {modified_formula}")
#     print(f"-> Alpha Zooì™€ì˜ ìœ ì‚¬ë„ ì ìˆ˜: {similarity2:.4f}")

#     # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: ì™„ì „íˆ ìƒˆë¡œìš´ êµ¬ì¡°ì˜ íŒ©í„°
#     new_formula = "rank(ts_corr(rank(low), rank(adv20), 5))" # ts_corrì€ ê°€ì •. correlationìœ¼ë¡œ í…ŒìŠ¤íŠ¸
#     new_formula_for_test = "rank(correlation(rank(low), rank(adv20), 5))" 
#     new_ast = parser.parse(new_formula_for_test)
#     similarity3 = originality_analyzer.calculate_similarity_score(new_ast)
#     print(f"\ní…ŒìŠ¤íŠ¸ ê³µì‹ 4 (ìœ ì‚¬ë„ ë‚®ìŒ ì˜ˆìƒ): {new_formula_for_test}")
#     print(f"-> Alpha Zooì™€ì˜ ìœ ì‚¬ë„ ì ìˆ˜: {similarity3:.4f} (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë…ì°½ì )")
# '''

# foundations/factor_structure.py
# foundations/factor_structure.py

import re
from typing import List, Union, Any, Set
from .alpha_zoo import get_alpha_zoo

# --- AST ë…¸ë“œ í´ë˜ìŠ¤ ì •ì˜ (ì´ì „ ì½”ë“œì™€ ë™ì¼) ---
class ASTNode:
    def __repr__(self):
        return self.__str__()
    
    def __hash__(self):
        return hash(str(self))

    def __eq__(self, other):
        return str(self) == str(other)

class OperatorNode(ASTNode):
    def __init__(self, op: str, children: List[ASTNode]):
        self.op = op
        self.children = children

    def __str__(self):
        children_str = ', '.join(map(str, self.children))
        return f"{self.op}({children_str})"

class VariableNode(ASTNode):
    def __init__(self, name: str):
        self.name = name

    def __str__(self):
        return f"${self.name}"

class LiteralNode(ASTNode):
    def __init__(self, value: Any):
        self.value = value

    def __str__(self):
        if isinstance(self.value, str):
            return f'"{self.value}"'
        return str(self.value)

# --- íŒ©í„° ê³µì‹ íŒŒì„œ ---
class FactorParser:
    def __init__(self):
        self.tokens = []
        self.pos = 0

    def parse(self, formula: str) -> ASTNode:
        self.tokens = self._tokenize(formula)
        self.pos = 0
        ast = self._parse_expression()
        if self.pos < len(self.tokens):
            raise ValueError("íŒŒì‹± í›„ ë‚¨ì€ í† í°ì´ ìˆìŠµë‹ˆë‹¤: {}".format(self.tokens[self.pos:]))
        return ast

    def _tokenize(self, formula: str) -> List[str]:
        # ğŸ’¡ ì‚¼í•­ ì—°ì‚°ìë¥¼ í¬í•¨í•œ ëª¨ë“  ì—°ì‚°ìë¥¼ ì •í™•íˆ íŒŒì‹±í•˜ë„ë¡ ì •ê·œì‹ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.
        token_regex = re.compile(r'([A-Za-z_][A-Za-z0-9_\.]*|\d+\.?\d*|==|!=|<=|>=|&&|\|\||[()+\-*/?^:,<>])')
        tokens = token_regex.findall(formula)
        return [token for token in tokens if token.strip() and token != '$']

    def _peek(self) -> Union[str, None]:
        return self.tokens[self.pos] if self.pos < len(self.tokens) else None

    def _consume(self) -> str:
        token = self._peek()
        self.pos += 1
        return token

    def _parse_primary(self) -> ASTNode:
        token = self._peek()
        if token == '-':
            self._consume()
            return OperatorNode('neg', [self._parse_primary()])
        if token.replace('.', '', 1).isdigit():
            return LiteralNode(float(self._consume()))
        if token.isalnum() or '_' in token or '.' in token:
            self._consume()
            if self._peek() == '(':
                self._consume()
                args = []
                if self._peek() != ')':
                    while True:
                        args.append(self._parse_expression())
                        if self._peek() == ')':
                            break
                        if self._peek() != ',':
                            raise ValueError("í•¨ìˆ˜ ì¸ì ì‚¬ì´ì— ì½¤ë§ˆ(,)ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                        self._consume()
                return OperatorNode(token, args)
            else:
                return VariableNode(token)
        if token == '(':
            self._consume()
            expr = self._parse_expression()
            if self._consume() != ')':
                raise ValueError("ê´„í˜¸ê°€ ë‹«íˆì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return expr
        raise ValueError(f"ì˜ˆìƒì¹˜ ëª»í•œ í† í°ì…ë‹ˆë‹¤: {token}")

    def _parse_binary_op(self, parse_next_level, ops: List[str]) -> ASTNode:
        node = parse_next_level()
        while self._peek() in ops:
            op = self._consume()
            right = parse_next_level()
            node = OperatorNode(op, [node, right])
        return node

    def _parse_power(self) -> ASTNode:
        return self._parse_binary_op(self._parse_primary, ['^'])

    def _parse_multiplicative(self) -> ASTNode:
        return self._parse_binary_op(self._parse_power, ['*', '/'])

    def _parse_additive(self) -> ASTNode:
        return self._parse_binary_op(self._parse_multiplicative, ['+', '-'])
        
    def _parse_comparison(self) -> ASTNode:
        return self._parse_binary_op(self._parse_additive, ['>', '<', '>=', '<=', '==', '!='])

    def _parse_logical(self) -> ASTNode:
        return self._parse_binary_op(self._parse_comparison, ['&&', '||'])

    def _parse_expression(self) -> ASTNode:
        node = self._parse_logical()
        if self._peek() == '?':
            self._consume()
            true_expr = self._parse_expression()
            if self._consume() != ':':
                raise ValueError("ì‚¼í•­ ì—°ì‚°ìì— ':'ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            false_expr = self._parse_expression()
            return OperatorNode('if', [node, true_expr, false_expr])
        return node

# --- íŒ©í„° ë³µì¡ë„ ë¶„ì„ê¸° (ì´ì „ ì½”ë“œì™€ ë™ì¼) ---
class ComplexityAnalyzer:
    def calculate_symbolic_length(self, node: ASTNode) -> int:
        if isinstance(node, OperatorNode):
            return 1 + sum(self.calculate_symbolic_length(child) for child in node.children)
        return 1

    def calculate_parameter_count(self, node: ASTNode) -> int:
        count = 0
        if isinstance(node, LiteralNode) and isinstance(node.value, (int, float)):
            count = 1
        if isinstance(node, OperatorNode):
            count += sum(self.calculate_parameter_count(child) for child in node.children)
        return count


# --- íŒ©í„° ë…ì°½ì„± ë¶„ì„ê¸° (ìˆ˜ì •ë¨) ---
class OriginalityAnalyzer:
    def __init__(self, parser: FactorParser, complexity_analyzer: ComplexityAnalyzer):
        self.parser = parser
        self.complexity_analyzer = complexity_analyzer
        self.alpha_zoo_asts = self._load_alpha_zoo_asts()

    def _load_alpha_zoo_asts(self) -> List[ASTNode]:
        formulas = get_alpha_zoo()
        asts = []
        for formula in formulas:
            try:
                asts.append(self.parser.parse(formula))
            except Exception as e:
                pass
        return asts

    def _get_all_subtrees(self, node: ASTNode) -> Set[ASTNode]:
        subtrees = {node}
        if isinstance(node, OperatorNode):
            for child in node.children:
                subtrees.update(self._get_all_subtrees(child))
        return subtrees

    def calculate_similarity_score(self, new_factor_ast: ASTNode) -> float:
        max_similarity = 0.0
        new_factor_subtrees = self._get_all_subtrees(new_factor_ast)
        size_new = self.complexity_analyzer.calculate_symbolic_length(new_factor_ast)

        for zoo_ast in self.alpha_zoo_asts:
            zoo_subtrees = self._get_all_subtrees(zoo_ast)
            
            common_subtrees = new_factor_subtrees.intersection(zoo_subtrees)
            
            if not common_subtrees:
                continue
            
            largest_common_subtree_size = 0
            for sub in common_subtrees:
                size = self.complexity_analyzer.calculate_symbolic_length(sub)
                if size > largest_common_subtree_size:
                    largest_common_subtree_size = size

            # ğŸ’¡ ë…¼ë¬¸ Eq.5ì— ë”°ë¼ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚° ë¡œì§ì„ ìˆ˜ì •
            size_zoo = self.complexity_analyzer.calculate_symbolic_length(zoo_ast)
            if max(size_new, size_zoo) > 0:
                similarity = largest_common_subtree_size / max(size_new, size_zoo)
            else:
                similarity = 0.0

            if similarity > max_similarity:
                max_similarity = similarity
        
        return max_similarity
