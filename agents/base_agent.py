# app.py (ìµœì¢… ìˆ˜ì • ì™„ë£Œ ë²„ì „)

import streamlit as st
import os
import pandas as pd
import numpy as np
import json
import re
from openai import OpenAI
import ast
import lightgbm as lgb
import logging
import time

# --- 0. Streamlit í˜ì´ì§€ ì„¤ì • ë° ë¡œê¹… ---
st.set_page_config(page_title="AlphaAgent", page_icon="ğŸ¤–", layout="wide")
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


# --- 1. OpenAI API í‚¤ ì„¤ì • ---
try:
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    logging.info("OpenAI API í‚¤ë¥¼ Streamlit secretsì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
except (KeyError, FileNotFoundError):
    logging.warning("Streamlit secretsì— OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì…ë ¥ì„ ë°›ìŠµë‹ˆë‹¤.")
    openai_api_key = st.text_input("OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.", type="password", key="api_key_input")
    if openai_api_key:
        client = OpenAI(api_key=openai_api_key)
    else:
        st.info("AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

# --- 2. í•µì‹¬ ë¡œì§ í•¨ìˆ˜ ë° í´ë˜ìŠ¤ (ìˆ˜ì • ì—†ìŒ) ---
# ì´ ë¶€ë¶„ì€ ì‚¬ìš©ìë‹˜ì˜ ì›ë³¸ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.

# ===================================================================================
# [ìˆ˜ì •ëœ ë¶€ë¶„ 1/2] ë°ì´í„° ë¡œë”© í•¨ìˆ˜ë¥¼ í›¨ì”¬ ë” ê°„ë‹¨í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.
# ===================================================================================
@st.cache_data(ttl=3600) # ë°ì´í„° ë¡œë”© ê²°ê³¼ë¥¼ 1ì‹œê°„ ë™ì•ˆ ìºì‹±
def load_pivoted_data(file_path: str):
    """
    í”„ë¡œì íŠ¸ í´ë” ë‚´ì— ìˆëŠ” ë‹¨ì¼ ë°ì´í„° íŒŒì¼(CSV)ì„ ì½ì–´ í”¼ë²— ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    logging.info(f"ë°ì´í„° íŒŒì¼ ë¡œë”© ì‹œì‘: {file_path}")
    try:
        # GitHubì— í•¨ê»˜ ì˜¬ë¦° CSV íŒŒì¼ì„ ì§ì ‘ ì½ìŠµë‹ˆë‹¤.
        df = pd.read_csv(file_path)
    except FileNotFoundError:
        st.error(f"ë°ì´í„° íŒŒì¼ '{file_path}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. app.pyì™€ ê°™ì€ í´ë”ì— íŒŒì¼ì´ ìˆëŠ”ì§€, GitHubì— í•¨ê»˜ ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None

    # ë°ì´í„° ì „ì²˜ë¦¬ (íŒŒì¼ì— 'ë‚ ì§œ' ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ ì´ë¦„ ë³€ê²½)
    if 'ë‚ ì§œ' in df.columns:
        df = df.rename(columns={'ë‚ ì§œ': 'date'})
        
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values(by=['date', 'symbol']).reset_index(drop=True)
    
    pivoted_data = {}
    # 'open', 'high', 'low', 'close', 'volume' ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  í”¼ë²—
    for col in ['open', 'high', 'low', 'close', 'volume']:
        if col in df.columns:
            pivoted = df.pivot(index='date', columns='symbol', values=col)
            pivoted_data[col] = pivoted.ffill().bfill() # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    
    if 'close' not in pivoted_data:
        st.error("í”¼ë²— ë°ì´í„° ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°ì— 'close'ì™€ 'symbol' ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
        
    logging.info(f"ğŸ“Š ì´ {len(pivoted_data['close'].columns)}ê°œ ì¢…ëª©ì˜ í”¼ë²— ë°ì´í„° ë¡œë”© ì™„ë£Œ")
    return pivoted_data

# (OPERATORS, execute_expression, prepare_base_features, AlphaZoo, QualityGate ë“± ëª¨ë“  í•µì‹¬ í•¨ìˆ˜/í´ë˜ìŠ¤ ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ê¸°)
OPERATORS = {'ts_mean': lambda df, window: df.rolling(window, min_periods=max(1, window//2)).mean(),'ts_std': lambda df, window: df.rolling(window, min_periods=max(1, window//2)).std(),'ts_rank': lambda df, window: df.rolling(window, min_periods=max(1, window//2)).rank(pct=True),'delay': lambda df, period: df.shift(period),'delta': lambda df, period: df.diff(period),'rank': lambda df: df.rank(axis=1, pct=True),'scale': lambda df: df.div(df.abs().sum(axis=1), axis=0),'add': lambda a, b: a + b,'subtract': lambda a, b: a - b,'multiply': lambda a, b: a * b,'divide': lambda a, b: a / b.replace(0, np.nan),'negate': lambda a: -a,'abs': lambda a: a.abs()}
def execute_expression(expression: str, data: dict):
    local_data = {k: v.copy() for k, v in data.items()}
    while '(' in expression:
        match = re.search(r"(\w+)\(([^()]+)\)", expression)
        if not match:
            if expression in local_data: return local_data[expression]
            raise ValueError(f"ì˜ëª»ëœ ìˆ˜ì‹ í˜•ì‹: {expression}")
        op_name, args_str = match.groups()
        args = [arg.strip() for arg in args_str.split(',')]
        evaluated_args = []
        for arg in args:
            if arg.isdigit(): evaluated_args.append(int(arg))
            elif arg in local_data: evaluated_args.append(local_data[arg])
            else: raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì¸ì '{arg}' (ìˆ˜ì‹: {expression})")
        if op_name in OPERATORS:
            temp_var_name = f"temp_{abs(hash(match.group(0)))}"
            local_data[temp_var_name] = OPERATORS[op_name](*evaluated_args)
            expression = expression.replace(match.group(0), temp_var_name, 1)
        else: raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì—°ì‚°ì: {op_name}")
    if expression in local_data: return local_data[expression]
    else: raise ValueError("ìµœì¢… ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def prepare_base_features(pivoted_data: dict) -> dict:
    logging.info("... ê¸°ë³¸ íŒ©í„°(Base Features) ìƒì„± ì¤‘ ...")
    data_copy = {k: v.copy() for k, v in pivoted_data.items()}
    pivoted_data['base_1'] = execute_expression("divide(subtract(close, open), open)", data_copy)
    pivoted_data['base_2'] = execute_expression("subtract(divide(close, delay(close, 1)), 1)", data_copy)
    pivoted_data['base_3'] = execute_expression("divide(volume, ts_mean(volume, 20))", data_copy)
    pivoted_data['base_4'] = execute_expression("divide(subtract(high, low), close)", data_copy)
    logging.info("âœ… ê¸°ë³¸ íŒ©í„° 4ê°œ ìƒì„± ì™„ë£Œ.")
    return pivoted_data
    
class AlphaZoo:
    def __init__(self): self.known_factors = {"ts_mean(close, 20)", "ts_std(close, 20)", "rank(volume)"}
    def add_factor(self, expression: str): self.known_factors.add(expression)
    def get_all_factors(self) -> set: return self.known_factors

class QualityGate:
    def __init__(self, alpha_zoo: AlphaZoo, client: OpenAI):
        self.alpha_zoo, self.client = alpha_zoo, client
        self.COMPLEXITY_THRESHOLD, self.ORIGINALITY_THRESHOLD, self.ALIGNMENT_THRESHOLD = 15, 0.9, 0.6
    def _calculate_complexity(self, expression: str) -> int:
        try: return sum(1 for node in ast.walk(ast.parse(expression)) if isinstance(node, (ast.Call, ast.Num, ast.Constant)))
        except: return float('inf')
    def _calculate_originality(self, expression: str) -> float:
        new_ops, max_similarity = set(re.findall(r'(\w+)\(', expression)), 0
        for known_expr in self.alpha_zoo.get_all_factors():
            known_ops = set(re.findall(r'(\w+)\(', known_expr))
            if not new_ops and not known_ops: continue
            intersection, union = len(new_ops.intersection(known_ops)), len(new_ops.union(known_ops))
            similarity = intersection / union if union > 0 else 0
            if similarity > max_similarity: max_similarity = similarity
        return max_similarity
    def _check_alignment(self, hypothesis: str, factor_expression: str) -> float:
        prompt = f"ë‹¤ìŒ 'ê°€ì„¤'ê³¼ 'íŒ©í„° ìˆ˜ì‹'ì˜ ë…¼ë¦¬ì  ì¼ì¹˜ë„ë¥¼ 0.0ì—ì„œ 1.0 ì‚¬ì´ì˜ ì ìˆ˜ë¡œë§Œ í‰ê°€í•´ì¤˜.\n- ê°€ì„¤: \"{hypothesis}\"\n- íŒ©í„° ìˆ˜ì‹: \"{factor_expression}\""
        try:
            response = self.client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": prompt}], temperature=0.0)
            return float(response.choices[0].message.content.strip())
        except Exception as e:
            logging.error(f"ì •í•©ì„± í‰ê°€ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return 0.0
    def validate(self, hypothesis: str, factor: dict) -> (bool, str):
        expression = factor['expression']
        complexity = self._calculate_complexity(expression)
        if complexity > self.COMPLEXITY_THRESHOLD: return False, f"ë³µì¡ë„ ì´ˆê³¼ ({complexity}/{self.COMPLEXITY_THRESHOLD})"
        similarity = self._calculate_originality(expression)
        if similarity > self.ORIGINALITY_THRESHOLD: return False, f"ë…ì°½ì„± ë¶€ì¡± (ìœ ì‚¬ë„ {similarity:.2f})"
        alignment_score = self._check_alignment(hypothesis, expression)
        if alignment_score < self.ALIGNMENT_THRESHOLD: return False, f"ì •í•©ì„± ë¶€ì¡± (ì ìˆ˜ {alignment_score:.2f})"
        return True, "í’ˆì§ˆ ê²€ì‚¬ í†µê³¼"

def generate_market_hypothesis(seed: str, feedback_history: list) -> str:
    system_prompt = "ë‹¹ì‹ ì€ ì£¼ì‹ ì‹œì¥ì„ ë¶„ì„í•˜ëŠ” í€€íŠ¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…Œë§ˆë‚˜ ì´ì „ì˜ ì„±ê³µ/ì‹¤íŒ¨ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ, ê²€ì¦ ê°€ëŠ¥í•œ ìƒˆë¡œìš´ ì •ëŸ‰ì  íˆ¬ì ê°€ì„¤ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”."
    user_content = f"í…Œë§ˆ: {seed}"
    if feedback_history:
        recent_feedback = "\n".join(feedback_history[-3:])
        user_content += f"\n\nì´ì „ ì‹œë„ì— ëŒ€í•œ í”¼ë“œë°±ì…ë‹ˆë‹¤:\n{recent_feedback}\n\nì´ í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ê¸°ì¡´ ì•„ì´ë””ì–´ë¥¼ ê°œì„ í•˜ê±°ë‚˜ ì™„ì „íˆ ìƒˆë¡œìš´ ë°©í–¥ì˜ ê°€ì„¤ì„ ì œì‹œí•´ì£¼ì„¸ìš”."
    response = client.chat.completions.create(model="gpt-4o", messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}], temperature=0.7)
    return response.choices[0].message.content.strip()

def generate_alpha_expression(hypothesis: str) -> dict:
    available_ops = ", ".join(OPERATORS.keys())
    system_prompt = f"ë„ˆëŠ” ì•ŒíŒŒ íŒ©í„° ìƒì„± AIì•¼. ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ê³¼ ì£¼ì–´ì§„ í‘œì¤€ ì—°ì‚°ìë§Œì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤.\n{{ \"description\": \"...\", \"expression\": \"...\" }}\n---\n[ì‚¬ìš© ê°€ëŠ¥ ì—°ì‚°ì] {available_ops}\n[ì‚¬ìš© ê°€ëŠ¥ ë°ì´í„°] open, high, low, close, volume\n[ê·œì¹™] í•¨ìˆ˜ í˜•íƒœë¡œ ì‘ì„±. ì˜ˆ: rank(subtract(ts_mean(close, 20), ts_mean(close, 60)))\n---"
    response = client.chat.completions.create(model="gpt-4o", messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": f"ê°€ì„¤: {hypothesis}"}], temperature=0.2)
    raw_response = response.choices[0].message.content.strip()
    match = re.search(r'\{.*\}', raw_response, re.DOTALL)
    if match: return json.loads(match.group(0))
    else: raise ValueError(f"JSON íŒŒì‹± ì˜¤ë¥˜: {raw_response}")

def evaluate_factor_with_lgbm(new_factor_values: pd.DataFrame, data: dict):
    LOOKBACK_WINDOW = 252
    feature_names = ['base_1', 'base_2', 'base_3', 'base_4']
    features = {name: data[name] for name in feature_names}
    features['new_factor'] = new_factor_values
    feature_dfs = [df.stack().rename(name) for name, df in features.items()]
    master_df = pd.concat(feature_dfs, axis=1)
    target = data['close'].pct_change().shift(-1).stack().rename('target')
    master_df = master_df.join(target, how='inner').dropna()
    if master_df.empty: return {'success': False, 'error': 'í”¼ì²˜ì™€ íƒ€ê²Ÿ ê²°í•© í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}
    all_predictions = []
    unique_dates = master_df.index.get_level_values('date').unique().sort_values()
    
    progress_bar = st.progress(0, text="ëª¨ë¸ ë°±í…ŒìŠ¤íŒ… ì§„í–‰ ì¤‘...")
    
    for i in range(LOOKBACK_WINDOW, len(unique_dates)):
        train_start_date, train_end_date, test_date = unique_dates[i - LOOKBACK_WINDOW], unique_dates[i - 1], unique_dates[i]
        train_slice, test_slice = master_df.loc[train_start_date:train_end_date], master_df.loc[test_date:test_date]
        if train_slice.empty or test_slice.empty: continue
        X_train, y_train = train_slice.drop('target', axis=1), train_slice['target']
        X_test, y_test = test_slice.drop('target', axis=1), test_slice['target']
        lgbm = lgb.LGBMRegressor(random_state=42, n_jobs=-1, n_estimators=100)
        lgbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], callbacks=[lgb.early_stopping(5, verbose=False)])
        predictions = pd.Series(lgbm.predict(X_test), index=X_test.index)
        all_predictions.append(predictions)
        
        progress_bar.progress((i - LOOKBACK_WINDOW + 1) / (len(unique_dates) - LOOKBACK_WINDOW), text=f"ëª¨ë¸ ë°±í…ŒìŠ¤íŒ… ì§„í–‰ ì¤‘... ({test_date.strftime('%Y-%m-%d')})")

    progress_bar.empty()
        
    if not all_predictions: return {'success': False, 'error': 'ë¡¤ë§ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.'}
    alpha_scores = pd.concat(all_predictions).unstack()
    future_returns = data['close'].pct_change().shift(-1)
    aligned_scores, aligned_returns = alpha_scores.align(future_returns, join='inner')
    if aligned_scores.empty: return {'success': False, 'error': 'ëª¨ë¸ ì˜ˆì¸¡ê°’ê³¼ ìˆ˜ìµë¥  ì •ë ¬ ì‹¤íŒ¨.'}
    long_mask, short_mask = aligned_scores.rank(axis=1, pct=True) > 0.8, aligned_scores.rank(axis=1, pct=True) < 0.2
    long_returns, short_returns = aligned_returns[long_mask].mean(axis=1), aligned_returns[short_mask].mean(axis=1)
    strategy_returns = long_returns - short_returns
    sharpe_ratio = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
    annual_return = strategy_returns.mean() * 252
    cumulative_returns = (1 + strategy_returns).cumprod()
    mdd = (cumulative_returns.cummax() - cumulative_returns).max()
    return {'success': True, 'sharpe_ratio': sharpe_ratio, 'annual_return': annual_return, 'mdd': mdd, 'cumulative_returns': cumulative_returns}

def generate_seed_from_user_idea(user_input: str) -> str:
    system_prompt = """
    ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ì˜ ìµœê³  í€€íŠ¸ ë¶„ì„ê°€ì´ì, ì´ˆë³´ íˆ¬ììë“¤ì´ ì•„ì´ë””ì–´ë¥¼ êµ¬ì²´í™”í•˜ë„ë¡ ë•ëŠ” ì¹œì ˆí•œ ì–´ë“œë°”ì´ì €ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ëŒ€í™”ë‚˜ ë‹¨í¸ì ì¸ ì•„ì´ë””ì–´ì—ì„œ í•µì‹¬ì„ íŒŒì•…í•˜ì—¬, AlphaAgentê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì •ëŸ‰ì  íˆ¬ì 'ì‹œë“œ(seed) ê°€ì„¤'ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ì œí•´ì•¼ í•©ë‹ˆë‹¤.
    """
    response = client.chat.completions.create(model="gpt-4o", messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_input}], temperature=0.1)
    return response.choices[0].message.content.strip()

# ===================================================================================
# [ìˆ˜ì •ëœ ë¶€ë¶„ 2/2] ì ˆëŒ€ ê²½ë¡œ ëŒ€ì‹ , íŒŒì¼ ì´ë¦„ì„ ì§ì ‘ ì „ë‹¬í•˜ë„ë¡ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.
# ===================================================================================
# --- 3. ë°ì´í„° ë¡œë”© (ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰) ---
pivoted_data = load_pivoted_data("ohlcv_data.csv")
if pivoted_data:
    pivoted_data = prepare_base_features(pivoted_data)
else:
    # load_pivoted_data í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì´ë¯¸ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ë³´ì—¬ì£¼ë¯€ë¡œ st.stop()ë§Œ í˜¸ì¶œ
    st.stop()


# --- 4. Streamlit UI êµ¬ì„± (ìˆ˜ì • ì—†ìŒ, ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼) ---
st.title("ğŸ¤– AlphaAgent: ë‚˜ë§Œì˜ íˆ¬ì ì „ëµ ìë™ íƒìƒ‰")
st.markdown("ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ë©´, AIê°€ ììœ¨ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ìµœì ì˜ íˆ¬ì íŒ©í„°(Alpha Factor)ë¥¼ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤.")

if 'best_factor' not in st.session_state:
    st.session_state.best_factor = {'sharpe': -np.inf}
if 'log_messages' not in st.session_state:
    st.session_state.log_messages = []
if 'analysis_done' not in st.session_state:
    st.session_state.analysis_done = False

st.subheader("1. ì•„ì´ë””ì–´ ì…ë ¥ ë° ì„¤ì •")
with st.form("input_form"):
    user_idea = st.text_area("ì–´ë–¤ íˆ¬ì ì „ëµì„ ì°¾ì•„ë³¼ê¹Œìš”?", "ì¡°ìš©í•˜ë˜ ì£¼ì‹ì´ ê°‘ìê¸° í™• íŠ€ëŠ” í˜„ìƒ", height=100)
    num_iterations = st.number_input("ëª‡ ë²ˆì˜ ì‹œë„ë¥¼ í†µí•´ ì „ëµì„ ê°œì„ í• ê¹Œìš”?", min_value=1, max_value=20, value=5)
    start_button = st.form_submit_button("âœ¨ ììœ¨ ë¶„ì„ ì‹œì‘!")

if start_button:
    st.session_state.analysis_done = True
    st.session_state.log_messages = []
    st.session_state.best_factor = {'sharpe': -np.inf}

    with st.status("1. AIê°€ ì•„ì´ë””ì–´ë¥¼ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ê°€ì„¤ë¡œ ë‹¤ë“¬ëŠ” ì¤‘...", expanded=True) as status:
        try:
            refined_seed = generate_seed_from_user_idea(user_idea)
            st.write(f"**ì •ì œëœ ê°€ì„¤:** *{refined_seed}*")
            status.update(label="âœ… ì•„ì´ë””ì–´ ì •ì œ ì™„ë£Œ!", state="complete")
        except Exception as e:
            st.error(f"ì•„ì´ë””ì–´ ì •ì œ ì‹¤íŒ¨: {e}")
            st.stop()
    
    log_container = st.container()
    feedback_history = []
    alpha_zoo = AlphaZoo()

    for i in range(1, num_iterations + 1):
        with st.status(f"2. ììœ¨ ë¶„ì„ ì§„í–‰ ì¤‘... [ë°˜ë³µ {i}/{num_iterations}]", expanded=True) as status:
            try:
                hypothesis = generate_market_hypothesis(refined_seed, feedback_history)
                st.write(f"ğŸ§  **ìƒì„±ëœ ê°€ì„¤:** {hypothesis}")
                
                factor = generate_alpha_expression(hypothesis)
                st.write(f"ğŸ“ **ìƒì„±ëœ íŒ©í„°:** `{factor['expression']}`")
                
                is_valid, reason = QualityGate(alpha_zoo, client).validate(hypothesis, factor)
                if not is_valid:
                    raise ValueError(f"í’ˆì§ˆ ê²€ì‚¬ ì‹¤íŒ¨: {reason}")
                
                factor_values = execute_expression(factor['expression'], pivoted_data)
                result = evaluate_factor_with_lgbm(factor_values, pivoted_data)
                
                if result['success']:
                    sharpe = result['sharpe_ratio']
                    feedback = f"ë°˜ë³µ {i}: íŒ©í„° '{factor['expression']}' -> Sharpe: {sharpe:.2f}."
                    feedback_history.append(feedback)
                    alpha_zoo.add_factor(factor['expression'])
                    
                    st.session_state.log_messages.append({
                        "iteration": i, "success": True, "hypothesis": hypothesis, 
                        "expression": factor['expression'], "sharpe": sharpe, "result": result
                    })

                    if sharpe > st.session_state.best_factor['sharpe']:
                        st.session_state.best_factor = {
                            'sharpe': sharpe, 'description': factor['description'], 
                            'expression': factor['expression'], 'result': result
                        }
                    
                    status.update(label=f"âœ… ë°˜ë³µ {i} ì„±ê³µ! (Sharpe: {sharpe:.2f})", state="complete")
                else:
                    raise ValueError(f"ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨: {result['error']}")

            except Exception as e:
                feedback = f"ë°˜ë³µ {i}: ì‹¤íŒ¨. ({str(e)})"
                feedback_history.append(feedback)
                st.session_state.log_messages.append({"iteration": i, "success": False, "error": str(e)})
                status.update(label=f"âŒ ë°˜ë³µ {i} ì‹¤íŒ¨", state="error")

    st.balloons()

if st.session_state.analysis_done:
    st.subheader("3. ë¶„ì„ ê²°ê³¼")

    best = st.session_state.best_factor
    if best['sharpe'] > -np.inf:
        st.success(f"ğŸ‰ **ìµœê³ ì˜ ì „ëµì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!** (Sharpe Ratio: {best['sharpe']:.3f})")
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ì—°ê°„ ìˆ˜ìµë¥ ", f"{best['result']['annual_return'] * 100:.2f} %")
            st.metric("ìµœëŒ€ ë‚™í­ (MDD)", f"{best['result']['mdd'] * 100:.2f} %")
        
        with col2:
            st.write("**ğŸ“ íŒ©í„° ì„¤ëª…**")
            st.info(f"{best['description']}")
            st.write("**âš™ï¸ íŒ©í„° ìˆ˜ì‹**")
            st.code(f"{best['expression']}", language="python")

        st.line_chart(best['result']['cumulative_returns'])

    else:
        st.error("ìœ ì˜ë¯¸í•œ ì „ëµì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì•„ì´ë””ì–´ë¥¼ ë°”ê¿” ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")

    with st.expander("ğŸ” ì „ì²´ ë¶„ì„ ê³¼ì • ë¡œê·¸ ë³´ê¸°"):
        for log in st.session_state.log_messages:
            if log['success']:
                st.markdown(f"--- \n**[ì„±ê³µ] ë°˜ë³µ #{log['iteration']} | Sharpe: {log['sharpe']:.3f}**")
                st.text(f"ê°€ì„¤: {log['hypothesis']}")
                st.code(f"ìˆ˜ì‹: {log['expression']}", language="python")
            else:
                st.markdown(f"--- \n**[ì‹¤íŒ¨] ë°˜ë³µ #{log['iteration']}**")
                st.error(f"ì˜¤ë¥˜: {log['error']}")
